# LASTEDOCATION ML Pipeline

Complete machine learning service integration for location prediction.

## ğŸ¯ Features

- **ML Service**: FastAPI + RandomForest + SQLite
- **Backend Integration**: TypeScript proxy with retry logic
- **Frontend UI**: React pages for training and prediction
- **Docker**: Full-stack orchestration
- **CI/CD**: GitHub Actions workflow
- **Monitoring**: Health checks and metrics
- **Benchmarking**: Performance testing tools

## ğŸ“¦ Components

### ML Service (Port 8000)
- RandomForest location prediction
- Async training with job tracking
- SQLite for persistence
- Model versioning
- REST API

### Backend (Port 3001)
- Express proxy at `/api/models/*`
- File upload handling
- Retry logic
- Authentication ready

### Frontend (Port 3000)
- Training page: `/ml-train`
- Prediction page: `/ml-predict`
- Real-time progress tracking
- Modern UI with TailwindCSS

## ğŸš€ Quick Start

### Development
\`\`\`bash
./start_dev.sh
\`\`\`

### Docker
\`\`\`bash
docker-compose up -d
\`\`\`

### Production
\`\`\`bash
docker-compose -f docker-compose.prod.yml up -d
\`\`\`

## ğŸ§ª Testing

### Unit Tests
\`\`\`bash
cd ml_service && python3 test_local.py
\`\`\`

### API Integration
\`\`\`bash
./test_ml_api.sh
\`\`\`

### Performance Benchmark
\`\`\`bash
python3 benchmark_ml.py
\`\`\`

### Health Monitor
\`\`\`bash
./monitor.sh
\`\`\`

## ğŸ“Š Sample Data

Generate test datasets:
\`\`\`bash
python3 generate_sample_data.py
\`\`\`

Files created:
- `sample_random_walk.csv` (500 rows)
- `sample_circular_path.csv` (200 rows)
- `sample_commute_pattern.csv` (300 rows)
- `sample_large_dataset.csv` (5000 rows)

## ğŸ“š Documentation

- **[API Examples](API_EXAMPLES.md)** - API usage and examples
- **[Deployment](DEPLOY.md)** - Production deployment guide
- **[ML Service](ml_service/README.md)** - ML service documentation
- **[Production Checklist](PRODUCTION_CHECKLIST.md)** - Go-live checklist

## ğŸ”§ Configuration

### ML Service
\`\`\`env
ML_SERVICE_PORT=8000
RANDOM_SEED=2025
N_ESTIMATORS=100
TEST_SIZE=0.2
N_JOBS=-1
MAX_UPLOAD_MB=50
\`\`\`

### Backend
\`\`\`env
ML_SERVICE_BASE_URL=http://ml_service:8000
PORT=3001
\`\`\`

### Frontend
\`\`\`env
VITE_API_BASE_URL=http://localhost:3001
\`\`\`

## ğŸ“ˆ Architecture

\`\`\`
Frontend (React)
    â†“
Backend (Express)
    â†“
ML Service (FastAPI)
    â†“
SQLite (jobs.db)
    â†“
Models (*.pkl)
\`\`\`

## ğŸ” Security

- SQLite with parameterized queries âœ“
- File size limits enforced âœ“
- CORS configured âœ“
- Helmet.js security headers âœ“
- Authentication ready (add JWT)
- Rate limiting ready (configure limits)

## ğŸš¦ Monitoring

Health endpoints:
- ML Service: `http://localhost:8000/health`
- Backend: `http://localhost:3001/api/health`
- Frontend: `http://localhost:3000`

Monitor script:
\`\`\`bash
./monitor.sh
\`\`\`

## ğŸ“Š Performance

Benchmarks (MacBook Pro M1):
- Training (1000 rows): ~2-3 seconds
- Prediction latency: <100ms (p95)
- Concurrent jobs: 3 (configurable)

## ğŸ› ï¸ Development

### Project Structure
\`\`\`
ml_service/          # Python ML service
  â”œâ”€â”€ config.py      # Settings
  â”œâ”€â”€ database.py    # SQLite operations
  â”œâ”€â”€ modeling.py    # ML training/prediction
  â”œâ”€â”€ app.py         # FastAPI server
  â””â”€â”€ test_local.py  # Local tests

BACKEND/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ services/mlProxy.ts  # ML client
  â”‚   â””â”€â”€ routes/models.ts     # API routes
  â””â”€â”€ Dockerfile

client/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ api/ml.ts           # API client
  â”‚   â””â”€â”€ pages/
  â”‚       â”œâ”€â”€ Train.tsx       # Training UI
  â”‚       â””â”€â”€ Predict.tsx     # Prediction UI
  â””â”€â”€ Dockerfile

docker-compose.yml        # Development
docker-compose.prod.yml   # Production
\`\`\`

## ğŸ“ License

MIT

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Add tests
4. Submit pull request

## ğŸ“ Support

- GitHub Issues
- Documentation: See `/docs`
- API Examples: `API_EXAMPLES.md`
